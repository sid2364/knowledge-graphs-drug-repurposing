{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee0ac511-c28b-4ba3-9196-e9940c2f7f04",
   "metadata": {},
   "source": [
    "Training KGEs(\n",
    "\n",
    "Refs:-\n",
    "https://mlflow.org/docs/latest/ml/tracking/quickstart/\n",
    "https://pykeen.readthedocs.io/en/stable/tutorial/models.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f919ddcb-5404-4eca-b3a1-3dde42f48a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import torch\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import mlflow\n",
    "from mlflow.models import infer_signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03d9947-de64-405d-8cea-c583d084d9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pykeen.triples import TriplesFactory\n",
    "from pykeen.pipeline import pipeline\n",
    "from pykeen.trackers import MLFlowResultTracker\n",
    "from pykeen.pipeline import pipeline\n",
    "from pykeen.trackers import MLFlowResultTracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73d759b-58ab-41d1-a800-50a94336c55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Device:\", DEVICE)\n",
    "SEED = 23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b007d910-3b0f-4a67-826f-789049d8dacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLFLOW_TRACKING_URI=\"file:./mlruns\"\n",
    "MLFLOW_EXPERIMENT=\"KGE Training (TransE, DistMult and ComplEx) with PharMeBINet\"\n",
    "\n",
    "# mlflow.set_tracking_uri(uri=\"http://127.0.0.1:8080\")\n",
    "mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
    "mlflow.set_experiment(MLFLOW_EXPERIMENT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9ec64a-eabb-4790-8ed1-2c6b47676dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = Path().resolve()/\"..\" # FIXME hacky way to go back, find a way to reference actual project root\n",
    "DATA_DIR = ROOT/\"data\"/\"processed\"/\"pharmebinet\"\n",
    "RUNS_DIR = ROOT/\"runs\"/\"pykeen_kge_pharmebinet\"\n",
    "RUNS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "TRIPLES = DATA_DIR/\"triples.tsv\"\n",
    "E2ID = DATA_DIR/\"entity2id.csv\"\n",
    "R2ID = DATA_DIR/\"relation2id.csv\"\n",
    "ETYPE = DATA_DIR/\"entity_types.csv\"\n",
    "\n",
    "# double check if it's all there\n",
    "for p in [TRIPLES, E2ID, R2ID, ETYPE]:\n",
    "    assert p.exists(), f\"Missing file: {p}\"\n",
    "\n",
    "# print(\"entity types\")\n",
    "# display(pd.read_csv(ETYPE, nrows=5))\n",
    "print(\"triples:\")\n",
    "display(pd.read_csv(TRIPLES, nrows=5))\n",
    "print(\"relation to ID\")\n",
    "display(pd.read_csv(R2ID, nrows=30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a5eec5-d2a5-43bd-b4d5-827aa6a923ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load mappings\n",
    "e2 = pd.read_csv(E2ID, dtype={\"entity_id\": str, \"idx\": int})\n",
    "r2 = pd.read_csv(R2ID, dtype={\"relation\": str, \"idx\": int})\n",
    "\n",
    "entity_to_id = dict(zip(e2[\"entity_id\"], e2[\"idx\"]))\n",
    "relation_to_id = dict(zip(r2[\"relation\"],  r2[\"idx\"]))\n",
    "\n",
    "# and triples (header: head, relation, tail) -------------------\n",
    "triples_df = pd.read_csv(TRIPLES, sep=\"\\t\", dtype=str, usecols=[\"head\", \"relation\", \"tail\"]) # pls don't crash\n",
    "labeled_triples = triples_df[[\"head\", \"relation\", \"tail\"]].values\n",
    "\n",
    "tf_all = TriplesFactory.from_labeled_triples(\n",
    "    triples=labeled_triples,\n",
    "    entity_to_id=entity_to_id,\n",
    "    relation_to_id=relation_to_id,\n",
    "    create_inverse_triples=False, # TODO what does this really do?\n",
    ")\n",
    "\n",
    "tf_train, tf_valid, tf_test = tf_all.split([0.6, 0.2, 0.2], random_state=SEED)\n",
    "# FIXME try different splits!!! 80/10/10\n",
    "\n",
    "print(f\"entities={tf_all.num_entities:,} relations={tf_all.num_relations:,}\")\n",
    "print(f\"triples ---> train={tf_train.num_triples:,} valid={tf_valid.num_triples:,} test={tf_test.num_triples:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d1bfa8-5e0b-4263-bd72-21692f57d8c9",
   "metadata": {},
   "source": [
    "Reference: https://pykeen.readthedocs.io/en/stable/api/pykeen.pipeline.pipeline.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0e9f62-6b32-454d-9802-2bc367870adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(name: str, model_kwargs: dict, use_inverses: bool, out_dir: Path):\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    tr = tf_train if not use_inverses else tf_train.create_inverse_triples()\n",
    "    va = tf_valid if not use_inverses else tf_valid.create_inverse_triples()\n",
    "    te = tf_test if not use_inverses else tf_test.create_inverse_triples()\n",
    "\n",
    "    # PyKEEN MLflow tracker (it starts/uses a run under the experiment)\n",
    "    run_name = f\"{name}-{datetime.now().strftime('%Y%m%d-%H%M%S')}\"\n",
    "    tracker = MLFlowResultTracker(\n",
    "        tracking_uri=MLFLOW_TRACKING_URI,\n",
    "        # experiment_id=MLFLOW_EXPERIMENT,\n",
    "        experiment_name=MLFLOW_EXPERIMENT,\n",
    "        tags={\"dataset\": \"PharMeBINet\", \"embedding_name\": name},\n",
    "    )\n",
    "\n",
    "    result = pipeline(\n",
    "        training=tr,\n",
    "        validation=va,\n",
    "        testing=te,\n",
    "        model=name,\n",
    "        model_kwargs=model_kwargs,\n",
    "        optimizer=\"Adam\",\n",
    "        optimizer_kwargs={\"lr\": 1e-3},\n",
    "        negative_sampler=\"basic\",\n",
    "        negative_sampler_kwargs={\"num_negs_per_pos\": 1},\n",
    "        training_kwargs={\"num_epochs\": 5, \"batch_size\": 1024, \"automatic_memory_optimization\": True},\n",
    "        evaluator_kwargs={\"filtered\": True},\n",
    "        device=DEVICE,\n",
    "        random_seed=SEED,\n",
    "        result_tracker=tracker,\n",
    "    )\n",
    "\n",
    "    # save artifacts locally \n",
    "    result.save_to_directory(out_dir)\n",
    "\n",
    "    # also log params/metrics/artifacts to the SAME MLflow run\n",
    "    # (PyKEEN should already logged losses/metrics over time but \n",
    "    # add hyperparams + artifacts + others?)\n",
    "    run_id = tracker.run.info.run_id\n",
    "    with mlflow.start_run(run_id=run_id):# attach to the active run\n",
    "        # Hyperparameters / switches\n",
    "        mlflow.log_params({\n",
    "            \"model\": name,\n",
    "            \"embedding_dim\": model_kwargs.get(\"embedding_dim\"),\n",
    "            \"scoring_fct_norm\": model_kwargs.get(\"scoring_fct_norm\"),\n",
    "            \"create_inverse_triples\": use_inverses,\n",
    "            \"lr\": 1e-3,\n",
    "            \"epochs\": 5,\n",
    "            \"batch_size\": 1024,\n",
    "            \"negatives_per_pos\": 1,\n",
    "            \"seed\": SEED,\n",
    "            \"device\": DEVICE,\n",
    "        })\n",
    "\n",
    "        # final (filtered) metrics snapshot since pykeen already gives us this\n",
    "        m = result.metric_results.to_dict()\n",
    "        mlflow.log_metrics({\n",
    "            \"filtered_mrr\": m.get(\"mrr\", float(\"nan\")),\n",
    "            \"filtered_hits@1\": m.get(\"hits_at_1\", float(\"nan\")),\n",
    "            \"filtered_hits@3\": m.get(\"hits_at_3\", float(\"nan\")),\n",
    "            \"filtered_hits@10\": m.get(\"hits_at_10\", float(\"nan\")),\n",
    "        })\n",
    "\n",
    "        # artifacts\n",
    "        mlflow.log_artifacts(str(out_dir)) # the whole run folder (model, metadata, etc.)\n",
    "        mlflow.log_artifact(str(TRIPLES))\n",
    "        mlflow.log_artifact(str(E2ID))\n",
    "        mlflow.log_artifact(str(R2ID))\n",
    "\n",
    "    print(f\"[{name}] run_id={run_id}\")\n",
    "    metrics = result.metric_results.to_dict()\n",
    "    print(f\"[{name}] filtered: MRR={metrics.get('mrr'):.4f}\"\n",
    "          f\"H@1={metrics.get('hits_at_1'):.4f}  H@10={metrics.get('hits_at_10'):.4f}\")\n",
    "    return result, run_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ce91f7-ec3d-4646-b7f9-15452dbf7bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = [\n",
    "    (\"TransE\",   {\"embedding_dim\": 128, \"scoring_fct_norm\": 1}, False), # TODO check 512 dim\n",
    "    #(\"DistMult\", {\"embedding_dim\": 256}, True), # TODO why inverse = True?\n",
    "    #(\"ComplEx\",  {\"embedding_dim\": 256}, True), # TODO why inverse = True?\n",
    "]\n",
    "\n",
    "runs = {}\n",
    "for name, mkw, inv in experiments:\n",
    "    print(f\"====Training {name}\")\n",
    "    out = RUNS_DIR/name.lower()\n",
    "    res, run_id = train_model(name, mkw, inv, out)\n",
    "    runs[name] = run_id\n",
    "\n",
    "pd.DataFrame({k: v.metric_results.to_dict() for k, v in results.items()}).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0764bbc-4422-4d79-8736-8019e5dbc058",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9623a0d-1cd5-4f28-b627-7e550024b56d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191f6d77-c636-4bd5-a1e8-c2c83f62959c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18bc8dd7-38ad-4e1d-ba81-fd6e14d0dcff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "KGDR",
   "language": "python",
   "name": "kgdr_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
