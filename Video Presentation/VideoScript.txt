Hello, I’m Siddharth Sahay. In this video, I'll be talking through my work so far on the topic of Knowledge Graphs and Drug Repurposing, in preparation for my master thesis next academic year.

> next slide

Here’s the outline for this short presentation. I’ll start with what drug repurposing is, followed by why we use knowledge graphs and knowledge graph embeddings. Then I’ll go over common techniques in the state of the art. I’ll also present a few public Knowledge Graphs that may be relevant to my work next year. After that, I’ll briefly touch on evaluation metrics, outline the main challenges in the field, and finally walk through a rough plan for execution over the next year.

> next slide

We currently recognize around 7,000 rare diseases, but fewer than 6% have approved therapies. Conventional drug pipelines can cost up to two and a half billion dollars per drug and take over a decade of lab work. Repurposing existing molecules can shortcut much of that cost, and time. But the search space of possible drug to disease links is enormous - which is where drug repurposing comes in. Specifically, using knowledge graphs and knowledge graph embeddings to organize this space and systematically identify candidate drugs that could treat existing diseases in new ways.

> next slide

To quickly recap what knowledge graphs are: imagine a large network where drugs, diseases, genes, and biological pathways are connected based on known relationships. Each connection encodes meaningful biological knowledge. This structure helps humans intuitively grasp complex relationships.

> next slide

The graph shown here is the schema of Hetionet, which is one of the largest public biomedical knowledge graphs. As you can see in Figure B, the gene-gene interaction network is among the densest, so is the anatomy network, which is highly connected. My work will focus on relating existing compounds or molecules to diseases.

> next slide

For machine learning models to make use of Knowledge Graphs, they need them in a form they can work with, this is where knowledge graph embeddings come in. Embeddings translate each node and edge into a high-dimensional vector space. This allows machine learning models to predict new drug-disease relationships that are not explicitly recorded. There are several embedding techniques that differ in how they represent the graph scoring function-based translational methods like TransE, ComplEx, and RotatE, and path-based methods like random walks.

> next slide

State-of-the-art techniques fall into a few broad families. First, traditional ML pipelines like DT2Vec+ use a Knowledge Graph Embedding method called node2vec to convert the Knowledge Graph into a 100-dimensional vector space and then use a classification model like XGBoost to predict whether a drug-disease pair is mutually relevant and in what way. Others—like DREAMwalk—use a path-based approach, adding semantic-guided teleportation to navigate dense protein-protein interaction networks. More recently, graph neural networks have gained popularity for their ability to directly learn from graph structure. Finally, there is also Large Language Model approaches — for example, DrugChat takes a molecule, encodes it using a pre-trained GNN, transforms it into a format suitable for the LLM, and then uses the prompt and embedding to generate a response.

> next slide

A general machine learning pipeline in this space looks a bit like this: take a KG, preprocess it, run it through an embedding model to get a vectorized form, and then feed that into a classifier.  This will serve as the base pipeline for my own work next year, which I’ll build on with further customizations where relevant.

> next slide

Interpretability is central to bioinformatics. It's not enough for models to make predictions—they need to explain why a certain drug might be effective for a disease. Clinicians need biological justifications before investing time in lab experiments.

> next slide

Of course, none of this works without high-quality data. We have several public biomedical knowledge graphs. Hetionet is widely used and includes tens of thousands of entities. Larger graphs like PharMeBINet and the Clinical Knowledge Graph have emerged more recently, with millions of nodes and hundreds of millions of edges.

> next slide

Evaluating model performance is essential. We typically assess how well a model distinguishes real drug-disease pairs from random ones. Metrics like Area under the ROC and Precision-Recall curves offer general accuracy insight. Ranking metrics like Hits@K are especially important clinically, as they tell us if the most promising drug candidates consistently show up near the top.

> next slide

Despite this progress, there are still major challenges. First, there's a structural bias — protein-protein interactions dominate, which can obscure clinically relevant drug-disease links. Second, keeping knowledge graphs up to date is difficult. Biomedical research moves fast, but incorporating new findings into graphs is slow and error-prone. Third, understanding relationships beyond a second-order neighborhood quickly becomes computationally expensive due to the combinatorial explosion. Finally, interpretability remains a challenge—most machine learning models weren’t designed with explainability in mind.

> next slide

Given all of the insights so far, my thesis year is divided into 4 clear stages. In the first quarter, I’ll benchmark and reproduce several embedding methods—like TransE, DistMult, ComplEx, and random walk-based approaches—under the same conditions for fair comparison. In the second quarter, I’ll investigate how these embeddings handle diseases linked to multiple gene variants, especially in the context of rare genetic disorders.

In Q3, I’ll either design or adapt a model that balances performance with a strong focus on interpretability. Finally, the last quarter will be dedicated to extensive testing, analysis, and writing, with enough buffer to deal with unexpected challenges.

> next slide

Thank you for listening. I'm excited to continue exploring this area in the coming year.
